{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc75adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76827212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55ee925bff3472fb2eefbb649721124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zoeir\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zoeir\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-l6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e92fbc659ca4f77b75967739d4a4ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab03f03ee16c41b58b1da380d794ab70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d1b8df148c4a58a3708f71568ced0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ca3e73d4e54dcab5b476fca885dd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e038b6d140942e7ba3f5faa004a2d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d410eb6daec4216b747745028464ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bf3e18b9774e75b41474979496156b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae3501ab1e469581f2b34b6e2a65a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae19595f5b744b5ab4ee61f25885f77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8755b38e26c44135879d9391037818da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CARREGAR MODELO\n",
    "modelo = SentenceTransformer('all-MiniLM-l6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab8be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frases teste\n",
    "frases = [\n",
    "    \"O gato subiu no telhado\",\n",
    "    \"Python é linguagem de programação\",\n",
    "    \"O felino escalou a casa\",\n",
    "    \"O cachorro escalou a casa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bcb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_busca = \"Um gato no topo da casa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ba3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = modelo.encode([frase_busca] + frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84401cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677 - O gato subiu no telhado\n",
      "0.203 - Python é linguagem de programação\n",
      "0.569 - O felino escalou a casa\n",
      "0.608 - O cachorro escalou a casa\n",
      "\n",
      " Maior valor = mais similar a 'Um gato no topo da casa'\n"
     ]
    }
   ],
   "source": [
    "# Calcular similaridades\n",
    "for i, frase in enumerate(frases):\n",
    "    sim = cosine_similarity([embeddings[0]], [embeddings[i+1]])[0][0]\n",
    "    print(f\"{sim:.3f} - {frase}\")\n",
    "print(f\"\\n Maior valor = mais similar a '{frase_busca}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"The cat climbed onto the roof\",\n",
    "    \"Python is a programming language\",\n",
    "    \"The feline climbed the house\",\n",
    "    \"The dog climbed the house.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cfda8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_busca = \"A cat on top of the house\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1136076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677 - O gato subiu no telhado\n",
      "0.203 - Python é linguagem de programação\n",
      "0.569 - O felino escalou a casa\n",
      "0.608 - O cachorro escalou a casa\n",
      "\n",
      " Maior valor = mais similar a 'A cat on top of the house'\n"
     ]
    }
   ],
   "source": [
    "# Calcular similaridades em ingles\n",
    "for i, frase in enumerate(frases):\n",
    "    sim = cosine_similarity([embeddings[0]], [embeddings[i+1]])[0][0]\n",
    "    print(f\"{sim:.3f} - {frase}\")\n",
    "print(f\"\\n Maior valor = mais similar a '{frase_busca}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3988b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "with open('Config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc63bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuração\n",
    "gemini_key = config['KEY']\n",
    "pasta_pdfs = \"./manuais\" \n",
    "CHROMA_PATH = \"./chroma_db\" #Pasta onde o chromadb sera salvo\n",
    "\n",
    "# Inicializar\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
    "                                google_api_key=gemini_key)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-l6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faae2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexa PDFs no ChromaDB\n",
    "def indexar_pdfs():\n",
    "    # Limpar banco existente (opcional)\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        print(\"Removendo banco de dados antigo...\")\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "   \n",
    "    # Carregar PDFs\n",
    "    documentos = []\n",
    "    for arquivo in glob.glob(\"./manuais/*.pdf\"):\n",
    "        print(f\"Carregando {os.path.basename(arquivo)}\")\n",
    "        loader = PyPDFLoader(arquivo)\n",
    "        pages = loader.load()\n",
    "       \n",
    "        # Adicionar metadados personalizados\n",
    "        for page in pages:\n",
    "            page.metadata['manual'] = os.path.basename(arquivo).replace('.pdf', '')\n",
    "            documentos.append(page)\n",
    "   \n",
    "    if not documentos:\n",
    "        print(\"Nenhum PDF encontrado na pasta ./manuais/\")\n",
    "        return\n",
    "   \n",
    "    # Criar vector store no ChromaDB\n",
    "    print(f\"Processando {len(documentos)} documentos...\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documentos,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        collection_name=\"manuais-empresa\"\n",
    "    )\n",
    "   \n",
    "    print(f\"Indexados {len(documentos)} documentos no ChromaDB!\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb4c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta simples\n",
    "def consultar(pergunta):\n",
    "    # Verificar se banco existe\n",
    "    if not os.path.exists(CHROMA_PATH):\n",
    "        return \"Execute 'indexar_pdfs()' primeiro para criar a base de conhecimento!\"\n",
    "   \n",
    "    # Conectar ao ChromaDB existente\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"manuais-empresa\"\n",
    "    )\n",
    "   \n",
    "    # Buscar documentos similares\n",
    "    results = vectorstore.similarity_search_with_score(pergunta, k=3)\n",
    "   \n",
    "    # Verificar se encontrou resultados\n",
    "    if not results:\n",
    "        return \"Não encontrei informações relevantes nos manuais.\"\n",
    "   \n",
    "    # Montar contexto\n",
    "    contexto = \"\"\n",
    "    for doc, score in results:\n",
    "        manual = doc.metadata.get('manual', 'Desconhecido')\n",
    "        texto = doc.page_content[:1000]  # Limitar texto\n",
    "        # ChromaDB usa distância (quanto menor, melhor), converter para similaridade\n",
    "        similaridade = 1 - score\n",
    "        contexto += f\"Manual {manual} (relevância: {similaridade:.2f}):\\n{texto}\\n\\n\"\n",
    "   \n",
    "    # Gerar resposta\n",
    "    prompt = f\"\"\"Com base nos manuais da empresa abaixo, responda de forma clara e prática:\n",
    "\n",
    "{contexto}\n",
    "\n",
    "Pergunta: {pergunta}\n",
    "\n",
    "Resposta baseada nos manuais:\"\"\"\n",
    "   \n",
    "    return gemini.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49a09952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexando os manuais...\n",
      "Removendo banco de dados antigo...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] O arquivo já está sendo usado por outro processo: './chroma_db\\\\8bfc1bbf-18b1-4411-b7f3-5abd1da58891\\\\data_level0.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexando os manuais...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m indexar_pdfs()\n",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m, in \u001b[0;36mindexar_pdfs\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(CHROMA_PATH):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemovendo banco de dados antigo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(CHROMA_PATH)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Carregar PDFs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m documentos \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\zoeir\\anaconda3\\Lib\\shutil.py:790\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;66;03m# can't continue even if onexc hook returns\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _rmtree_unsafe(path, onexc)\n",
      "File \u001b[1;32mc:\\Users\\zoeir\\anaconda3\\Lib\\shutil.py:629\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 629\u001b[0m             onexc(os\u001b[38;5;241m.\u001b[39munlink, fullname, err)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mc:\\Users\\zoeir\\anaconda3\\Lib\\shutil.py:625\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    623\u001b[0m fullname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, name)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] O arquivo já está sendo usado por outro processo: './chroma_db\\\\8bfc1bbf-18b1-4411-b7f3-5abd1da58891\\\\data_level0.bin'"
     ]
    }
   ],
   "source": [
    "print(\"Indexando os manuais...\")\n",
    "indexar_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73bf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47fe0164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Como reiniciar o computador?\n",
      "Para reiniciar o computador, siga o procedimento: Menu Iniciar > Energia > Reiniciar (Manual MANUAL_COMPUTADOR).\n",
      "\n",
      "Qual a senha da impressora?\n",
      "Os manuais fornecidos não contêm informações sobre a senha da impressora.\n",
      "\n",
      "Como limpar teclado?\n",
      "Para limpar o teclado:\n",
      "\n",
      "1.  **Desconecte** o teclado do computador.\n",
      "2.  **Vire-o de cabeça para baixo** e balance suavemente para remover detritos soltos.\n",
      "3.  Use **ar comprimido** entre as teclas para remover poeira e sujeira.\n",
      "4.  Limpe a superfície com **álcool isopropílico**.\n",
      "5.  **Nunca use água diretamente** no teclado.\n",
      "\n",
      "Começei hoje no trabalho, qual é o horário do almoço?\n",
      "O horário de almoço é das 12h às 13h, de acordo com o manual NORMAS_EMPRESA.\n"
     ]
    }
   ],
   "source": [
    "perguntas = [\n",
    "    \"Como reiniciar o computador?\",\n",
    "    \"Qual a senha da impressora?\",\n",
    "    \"Como limpar teclado?\",\n",
    "    \"Começei hoje no trabalho, qual é o horário do almoço?\"\n",
    "]\n",
    "\n",
    "for p in perguntas:\n",
    "    print(f\"\\n{p}\")\n",
    "    print(f\"{consultar(p)}\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b8766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
